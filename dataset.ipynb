{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c4589bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "from PIL import Image, ImageDraw, ImageOps\n",
    "\n",
    "class ClimbingHoldDataset(Dataset):\n",
    "    def __init__(self, annotations_dir, images_dir, output_size=(128, 128)):\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            ),\n",
    "        ])\n",
    "        self.output_size = output_size\n",
    "        self.holds = []\n",
    "\n",
    "        for json_file in os.listdir(annotations_dir):\n",
    "            if json_file.endswith(\".json\"):\n",
    "                json_path = os.path.join(annotations_dir, json_file)\n",
    "                with open(json_path, 'r') as file:\n",
    "                    data = json.load(file)\n",
    "\n",
    "                images = {img['id']: img['file_name'] for img in data.get('images', [])}\n",
    "                annotations = data.get('annotations', [])\n",
    "                difficulties = {cat['id']: cat['name'] for cat in data.get('categories', [])}\n",
    "\n",
    "                for annotation in annotations:\n",
    "                    file_name = images.get(annotation.get(\"image_id\"))\n",
    "                    hold_data = {\n",
    "                        \"image_id\": file_name,\n",
    "                        \"difficulty\": difficulties.get(annotation.get(\"category_id\")),\n",
    "                        \"type\": annotation[\"attributes\"].get(\"Type\"),\n",
    "                        \"orientation\": annotation[\"attributes\"].get(\"Orientation\"),\n",
    "                        \"bbox\": annotation.get(\"bbox\"),\n",
    "                        \"segmentation\": annotation.get(\"segmentation\"),\n",
    "                    }\n",
    "                    self.holds.append(hold_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.holds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hold_data = self.holds[idx]\n",
    "        image_id = hold_data[\"image_id\"]\n",
    "        image_path = os.path.join(self.images_dir, image_id)\n",
    "        image = Image.open(image_path)\n",
    "        rotated_image = ImageOps.exif_transpose(image)\n",
    "\n",
    "        bbox = hold_data[\"bbox\"]\n",
    "        x_min, y_min, width, height = bbox\n",
    "        cropped_image = rotated_image.crop((x_min, y_min, x_min + width, y_min + height))\n",
    "        cropped_image = cropped_image.resize(self.output_size)\n",
    "\n",
    "        if self.transform:\n",
    "            cropped_image = self.transform(cropped_image)\n",
    "\n",
    "        return {\n",
    "            \"image\": cropped_image,\n",
    "            \"type\": self._map_type(hold_data[\"type\"]),\n",
    "            \"orientation\": self._map_orientation(hold_data[\"orientation\"]),\n",
    "        }\n",
    "\n",
    "    def _map_type(self, type_label):\n",
    "        types = ['Jug', 'Sloper', 'Crimp', 'Jib', 'Pinch', 'Pocket', 'Edge']\n",
    "        return types.index(type_label) if type_label in types else -1\n",
    "\n",
    "    def _map_orientation(self, orientation_label):\n",
    "        orientations = ['Up', 'Down', 'Side', 'UpAng', 'DownAng']\n",
    "        return orientations.index(orientation_label) if orientation_label in orientations else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6a343ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 1605\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/images/IMG_8293.jpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m dataset = ClimbingHoldDataset(annotations_dir, images_dir)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDataset size:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(dataset))\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m sample = \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mImage tensor shape:\u001b[39m\u001b[33m\"\u001b[39m, sample[\u001b[33m\"\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m\"\u001b[39m].shape)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mType index:\u001b[39m\u001b[33m\"\u001b[39m, sample[\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mClimbingHoldDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     49\u001b[39m image_id = hold_data[\u001b[33m\"\u001b[39m\u001b[33mimage_id\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     50\u001b[39m image_path = os.path.join(\u001b[38;5;28mself\u001b[39m.images_dir, image_id)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m image = \u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m rotated_image = ImageOps.exif_transpose(image)\n\u001b[32m     54\u001b[39m bbox = hold_data[\u001b[33m\"\u001b[39m\u001b[33mbbox\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/PIL/Image.py:3493\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3491\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_path(fp):\n\u001b[32m   3492\u001b[39m     filename = os.fspath(fp)\n\u001b[32m-> \u001b[39m\u001b[32m3493\u001b[39m     fp = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3494\u001b[39m     exclusive_fp = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3495\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/images/IMG_8293.jpeg'"
     ]
    }
   ],
   "source": [
    "annotations_dir = \"data/annotations\"\n",
    "images_dir = \"data/images\"\n",
    "\n",
    "dataset = ClimbingHoldDataset(annotations_dir, images_dir)\n",
    "\n",
    "print(\"Dataset size:\", len(dataset))\n",
    "\n",
    "sample = dataset[0]\n",
    "\n",
    "print(\"Image tensor shape:\", sample[\"image\"].shape)\n",
    "print(\"Type index:\", sample[\"type\"])\n",
    "print(\"Orientation index:\", sample[\"orientation\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
