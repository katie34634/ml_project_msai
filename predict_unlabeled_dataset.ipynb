{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a566fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models import ResNet50_Weights\n",
    "\n",
    "from create_dataset import ClimbingHoldDataset, ClimbingHoldDatasetPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b94dda07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Choose device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Apple Silicon\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Evaluation transform (no heavy augmentations)\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f287c007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in NEW dataset: 4541\n"
     ]
    }
   ],
   "source": [
    "annotations_dir = \"hold_preds\"  # <-- change this\n",
    "images_dir = \"data/images\"            # <-- change this\n",
    "\n",
    "dataset = ClimbingHoldDatasetPred(\n",
    "    annotations_dir=annotations_dir,\n",
    "    images_dir=images_dir,\n",
    "    output_size=(IMG_SIZE, IMG_SIZE),\n",
    ")\n",
    "\n",
    "dataset.transform = eval_transform  # use eval transform\n",
    "\n",
    "print(\"Total samples in NEW dataset:\", len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "209929c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoHeadResNet50(nn.Module):\n",
    "    def __init__(self, num_types=7, num_orientations=5, pretrained=False, dropout=0.3):\n",
    "        super().__init__()\n",
    "        weights = ResNet50_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "        backbone = models.resnet50(weights=weights)\n",
    "\n",
    "        in_features = backbone.fc.in_features\n",
    "        backbone.fc = nn.Identity()\n",
    "        self.backbone = backbone\n",
    "\n",
    "        self.type_head = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, num_types),\n",
    "        )\n",
    "\n",
    "        self.orientation_head = nn.Sequential(\n",
    "            nn.Linear(in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, num_orientations),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = self.backbone(x)\n",
    "        type_logits = self.type_head(feats)\n",
    "        orientation_logits = self.orientation_head(feats)\n",
    "        return type_logits, orientation_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f907e4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trained model from best_hold_model.pth\n"
     ]
    }
   ],
   "source": [
    "num_types = 7\n",
    "num_orients = 5\n",
    "\n",
    "model = TwoHeadResNet50(\n",
    "    num_types=num_types,\n",
    "    num_orientations=num_orients,\n",
    "    pretrained=False,  # weights come from checkpoint\n",
    "    dropout=0.3,\n",
    ").to(device)\n",
    "\n",
    "state_dict = torch.load(\"best_hold_model.pth\", map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Loaded trained model from best_hold_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e0f70e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted types shape   : (4541,)\n",
      "Predicted orients shape : (4541,)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "all_pred_types = []\n",
    "all_pred_orients = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        imgs = batch[\"image\"].to(device)  # from __getitem__\n",
    "        out_type, out_orient = model(imgs)\n",
    "\n",
    "        pred_type_batch = out_type.argmax(1).cpu().numpy()\n",
    "        pred_orient_batch = out_orient.argmax(1).cpu().numpy()\n",
    "\n",
    "        all_pred_types.append(pred_type_batch)\n",
    "        all_pred_orients.append(pred_orient_batch)\n",
    "\n",
    "pred_type_idx = np.concatenate(all_pred_types)   # shape (N,)\n",
    "pred_orient_idx = np.concatenate(all_pred_orients)\n",
    "\n",
    "print(\"Predicted types shape   :\", pred_type_idx.shape)\n",
    "print(\"Predicted orients shape :\", pred_orient_idx.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98f69f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pred_type_idx.npy and pred_orient_idx.npy\n"
     ]
    }
   ],
   "source": [
    "np.save(\"pred_type_idx.npy\", pred_type_idx)\n",
    "np.save(\"pred_orient_idx.npy\", pred_orient_idx)\n",
    "\n",
    "print(\"Saved pred_type_idx.npy and pred_orient_idx.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eae805b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
